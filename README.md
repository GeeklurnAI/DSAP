# Data Science Architect Program Plan

# Milestones

Milestone1 “Intro to Stats and Language of DataScience”
 
Milestone2 “EDA methods and Python”

Milestone3 “Intro to Machine Learning

Milestone4 “Natural Language Processing”

Milestone5 “RL,DL,DRL”

Total planned time: 22-weeks


 1)Intro to Stats and Language of DataScience
 -Data Scientist Roles 
 -Machine Learning 
 -Applications of Machine Learning 
 -WhyMachine Learning is the Future 
 -Data Analytics Lifecycle 
 -Statistics 
 -Different Python Modules Used for DataScience
  
Statistics & Probability
-Descriptive Statistics and Inferential Statistics 
-Sample and Population 
-Variables and DataTypes 
-Percentiles 
-Measure of Central Tendency 
-Measures of Spread 
-Skewness,Kurtosis 
-Sampling Distribution 
-Introduction to Probability,Discrete and Continous Distributions -Standard Probability Distribution Functions 
-Bernoulli,Binomial-Distributions 
-Descriptive Statistics and Inferential Statistics in Python 
-Normal Distributions 
-Test of Hypothesis-ZTest,T-TestandChi-squareTest 
-Confidence Interval 
-Variance,Covariance,Correlation 
-Degrees of Freedom 
-Annova Test 
-Important Interview Questions-Discussion

2)EDAMethodsandPython

-OverviewofPython 
-DifferentApplicationswherePythonisUsed -FundamentalsofPythonProgramming 
-Values,Types,Variables 
-ConditionalStatements 
-TheCompaniesusingPython 
-DiscussPythonScriptsonUNIX/Windows -OperationsandExpressions 
-Loops 
-WritingtotheScreen 
-Creatingthe“HelloWorld”Code 
-DemonstratingConditionalStatements 
-DemonstratingLoops

IntrotoLibraries-Numpy,Pandas,Matplotlib EDAandDataVisualization-UsingPythonLibraries
-DataTransformations 
-OutlierDetectionandManagement -ChartsandGraphs 
-OneDimensionalChart 
-Boxplots 
-Bargraph 
-Histogram 
-Scatterplots 
-Multi-DimensionalCharts

Module2:ARefreshertoPython
-InstallationStepsforMac 
-PackagesInstallation 
-IntroductiontoPython 
-Exercise:VariablesandOperators -Exercise:PythonLists
-Exercise:Dictionaries 
-DifferentApplicationswherePythonisUsed -ConditionalStatements 
-Values,Types,Variables 
-ConditionalStatements 
-Exercise:Loops 
-PythonFunctionsPractice 
-Exercise:Packages

SequencesandFileOperations
-PythonFiles1/10Functions 
-OutlierDetectionandManagement 
-List-Properties,RelatedOperations 
-Tuple-Properties,RelatedOperations 
-Set-Properties,RelatedOperations 
-Dictionary-Properties,RelatedOperations -Numbers

IntroductiontoNumPy,PandasandMatplotlib
-ReadingandWritingArraysonFiles 
-NumPyLibrary-CreatingNumPyArray 
-BarGraph,aPieCharttoShowInformation -PandasLibrary-CreatingSeriesandData

DataManipulation
-ConcatenationofDataObjects 
-ExploringaDataset 
-MergingofDataobjects 
-Aggregation 
-Analysingadataset 
-PandasFunction 

IntroductiontoMachineLearningwithPython
-PythonRevision(Numpy,Pandas,ScikitLearn,Matplotlib) -MachineLearningUse-Cases 
-MachineLearningCategories 
-GradientDescent 
-WhatisMachineLearning? 
-MachineLearningProcessFlow 
-MachineLearningtypes 
-Linearregression

Module3:LearntouseRegularExpressions
-UnderstandingRegularExpression 
-ImplementingRegularExpressioninPython 
-RegularExpressionsinAction

# 3)	Intro to Machine Learning

Introduction
-	Machine Learning - Concepts and Methods
-	Supervised and Unsupervised Learning
-	What is Machine Learning?
-	Machine Learning Process Flow
-	Machine Learning types

Module 9 : Machine Learning Algorithms (Structured data algorithms)
-	Types of Machine Learning Algorithms
-	Logistic Regression
-	Decision Tree
-	Naive Bayes
-	SVM (Support Vector Machine)
-	Random Forest

Supervised Learning - 1
-	Implementing Different Types of Supervised Learning Algorithms
-	What are Classification and its Use Cases?
-	Confusion Matrix
-	Evaluating model output
-	Implementation of Logistic regression
-	What is Decision Tree?
-	Algorithm for Decision Tree Induction
-	Creating a Perfect Decision Tree
-	What is a Random Forest?
-	Advanced Methods in Machine Learning
-	Dimensionality Reduction

Dimensionality Reduction
-	Introduction to Dimensionality
-	Why Dimensionality Reduction
-	Implementing Dimensionality Reduction Technique
-	PCA
-	Scaling Dimensional Model
-	Factor Analysis
-	LDA
-	Feature Engineering
-	Regularization
-	Underfitting Vs Overfitting
-	Boosting Bagging and Random Forest
-	Cross Validation

Model Selection and Boosting
-	What is the Model Selection?
-	The need for Model Selection
-	Cross-Validation
-	What is Boosting?
-	How Boosting Algorithms work?
-	Types of Boosting Algorithms
-	Adaptive Boosting
-	AdaBoost

Unsupervised Learning
-	What is Clustering & its Use Cases?
-	What is K-means Clustering?
-	How does the K-means algorithm work?
-	Implementing K-means Clustering
-	What is C-means Clustering?
-	Implementation of Clustering - various types
-	What is Hierarchical Clustering?
-	Implementing Hierarchical Clustering
-	How to do optimal clustering


Association Rules Mining and Recommendation Systems

-	What is Time Series Analysis?
-	Components of TSA
-	Importance of TSA
-	TSA in Python
-	TSA Forecasting
-	AR model
-	MA model
-	ARMA model
-	ARIMA model
-	Generating the ARIMA plot
-	Stationarity
-	Converting a non- stationary data to stationary
-	ACF & PACF
-	Plot ACF and PACF
-	Implementing the Dickey-Fuller Test

# 4)	Natural Language Processing

Module 4 : First Step of NLP - Text Processing (NLTK)
-	Tokenization and Text Normalisation
-	Exercise: Tokenisation and Text Normalisation
-	Exploring Text Data
-	Part of Speech Tagging and Grammar Parsing
-	Exercise: Part of Speech Tagging and Grammar Parsing
-	Implementing Text Pre-processing Using NLTK
-	Exercise: Implementing Text Pre-processing Using NLTK
-	Natural Language Processing Techniques Using spaCy

Module 6 : Feature Engineering for Text
-	Introduction to Text Feature Engineering
-	Count Vector, TFIDF Representations of Text
-	Exercise: Introduction to Text Feature Engineering
-	Understanding Vector Representation of Text
-	Exercise: Understanding Vector Representation of Text
-	Understanding Word Embeddings
-	Word Embeddings in Action - Word2Vec
-	Word Embeddings in Action - Glove

Module 7 : Mastering the Art of Text Cleaning
-	Introduction to Text Cleaning Techniques Part 1
-	Exercise: Introduction to Text Cleaning Techniques Part 1
-	Introduction to Text Cleaning Techniques Part 2
-	Text Cleaning Implementation
-	Exercise: Text Cleaning Implementation
-	NLP Techniques using spaCy

Module 5 : Extracting Named Entities from Text
-	Understanding Named Entity Recognition
-	Exercise: Understanding Named Entity Recognition
-	Implementing Dimensionality Reduction Technique
-	Exercise: Implementing Named Entity Recognition
-	Named Entity Recognition and POS tagging using spaCy
-	POS and NER in Action: Text Data Augmentation

Module 8 : Interpreting Patterns from Text - Topic Modelling
-	Introduction to Topic Modelling
-	Exercise: Introduction to Topic Modelling
-	Understanding LDA
-	Exercise: Understanding LDA
-	Implementation of Topic Modelling
-	LSA for Topic Modelling

Module 10 : Understanding Text Classification
-	Overview of Text Classification
-	Assignment: Share your learning and build your profile

Module 14 : Introduction to Language Modelling in NLP
-	Overview: Language Modelling
-	What is a Language Model in NLP?
-	N-gram Language Model
-	Implementing an N- gram Language Model - |
-	Implementing an N-gram Language Model - II
-	Neural Language Model
-	Implementing a Neural Language Model

Module 15 : Sequence-to-Sequence Modelling
-	Intuition Behind Sequence-to-Sequence Modelling
-	Need for Sequence-to-Sequence Modelling
-	Understanding the Architecture of Sequence-to-Sequence
-	Understanding the Functioning of Encoder and Decoder
-	Case Study: Building a Spanish to English Machine Translation Model
-	Preprocessing of Text Data
-	Converting Text to Integer Sequences
-	Model Building and Inference

Module 16 : Bonus Section (Advance NLP tools)
-	Text Classification & amp; Word Representations using FastText (An NLP library by Facebook)
-	Introduction to Flair for NLP: A Simple yet Powerful State-of-the-Art NLP Library
-	A Step-by-Step NLP Guide to Learn Elmo for Extracting Features from Text
-	8 Excellent Pretrained Models to get you started with Natural Language Processing (NLP)

Module 16 : Bonus SectioNatural Language Processing with deep Learning in Pythonn (Advance NLP tools)
-	Understand and implement word2vec
-	Understand the CBOW method in word
-	Understand the skip-gram method in word2vec
-	Understand the negative sampling optimisation in word2vec
-	Understand and implement GloVe using gradient descent and alternating least squares
-	Use recurrent neural networks for parts-of-speech tagging
-	Use recurrent neural networks for named entity recognition
-	Understand and implement recursive neural and neural tensor networks for sentiment analysis

# 5)	RL, DL, DRL

Reinforcement Learning
-	What is Reinforcement Learning
-	Elements of Reinforcement Learning
-	Why Reinforcement Learning
-	Implement Reinforcement Learning using Python
-	Epsilon Greedy Algorithm
-	Q values and V values and A values
-	Q- Learning
-	Implementing Q Learning
-	Developing Q Learning model in Python"
-	Exploration vs Exploitation dilemma
-	Markov Decision Process (MDP)
-	Calculating Reward
-	Calculating Optimal quantities
-	Setting up an Optimal Action
-	Discounted Reward
-	Implementing Q Learning"

Module 11 : Introduction to Deep Learning
etting started with Neural Network
-	Exercise: Getting started with Neural Network"
-	Understanding Forward Propagation
-	Exercise: Forward Propagation"
-	Math Behind forwarding Propagation
-	Exercise: Math Behind forwarding Propagation"
-	Error and Reason for Error
-	Exercise: Error and Reason for Error"
-	Gradient Descent Intuition
-	Optimiser
-	Back Propagation
-	Why Keras?
-	Building a Neural Network for Text Classification
-	Why CNN?
-	Understanding the working of CNN Filters"
-	Padding Strategies
-	Padding Strategies in Keras
-	Introduction to Pooling
-	CNN architecture and it's working

Module 12 : Deep Learning for NLP
-	Deep Learning for NLP Part 1
-	Deep Learning for NLP Part 2
-	Text Generation Using LSTM

Module 13: Recurrent Neural Networks
-	Why RNN
-	Introduction to RNN: Shortcomings of an MLP
-	Introduction to RNN: RNN Architecture
-	Training an RNN: Forward propagation
-	Training an RNN: Back propagation through time
-	Need for LSTM/GRU
-	Long Short Term Memory (LSTM)
-	Gated Recurrent Unit (GRU)





